{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jamess200/MyBirdNetTest/blob/main/merge_csv_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tbKUemG3l9p",
        "outputId": "8a92617f-e9af-4bd9-b04c-7c37118ba78e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKqvX2HR2zC-",
        "outputId": "301ebe4b-c266-4b11-bea1-5ff95d05c54b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects:   8% (1/12)\u001b[K\rremote: Counting objects:  16% (2/12)\u001b[K\rremote: Counting objects:  25% (3/12)\u001b[K\rremote: Counting objects:  33% (4/12)\u001b[K\rremote: Counting objects:  41% (5/12)\u001b[K\rremote: Counting objects:  50% (6/12)\u001b[K\rremote: Counting objects:  58% (7/12)\u001b[K\rremote: Counting objects:  66% (8/12)\u001b[K\rremote: Counting objects:  75% (9/12)\u001b[K\rremote: Counting objects:  83% (10/12)\u001b[K\rremote: Counting objects:  91% (11/12)\u001b[K\rremote: Counting objects: 100% (12/12)\u001b[K\rremote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects:  11% (1/9)\u001b[K\rremote: Compressing objects:  22% (2/9)\u001b[K\rremote: Compressing objects:  33% (3/9)\u001b[K\rremote: Compressing objects:  44% (4/9)\u001b[K\rremote: Compressing objects:  55% (5/9)\u001b[K\rremote: Compressing objects:  66% (6/9)\u001b[K\rremote: Compressing objects:  77% (7/9)\u001b[K\rremote: Compressing objects:  88% (8/9)\u001b[K\rremote: Compressing objects: 100% (9/9)\u001b[K\rremote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 9 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), 109.17 KiB | 59.00 KiB/s, done.\n",
            "From https://github.com/Jamess200/MyBirdNetTest\n",
            "   8006b68..e310bf8  main       -> origin/main\n",
            "Updating 8006b68..e310bf8\n",
            "Fast-forward\n",
            " Density_plot_code.ipynb | 5335 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m-\u001b[m\n",
            " Inital_BN_Test.ipynb    | 1004 \u001b[32m+++\u001b[m\u001b[31m----------\u001b[m\n",
            " 2 files changed, 5506 insertions(+), 833 deletions(-)\n",
            "data\t\t\t img\t\t       json_to_csv_converter.ipynb  Time_Test_BN_Test.ipynb\n",
            "Density_plot_code.ipynb  Inital_BN_Test.ipynb  README.md\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define path in Google Drive where you want to clone the repository\n",
        "repo_path = '/content/drive/MyDrive/'\n",
        "\n",
        "# Check if directory already exists\n",
        "if not os.path.exists(repo_path):\n",
        "    os.makedirs(repo_path)\n",
        "\n",
        "# Change working directory to defined path\n",
        "os.chdir(repo_path)\n",
        "\n",
        "# Clone the repository if doesnt exist, otherwise pull latest changes\n",
        "if not os.path.exists(os.path.join(repo_path, 'MyBirdNetTest')):\n",
        "    !git clone https://github.com/Jamess200/MyBirdNetTest.git\n",
        "else:\n",
        "    os.chdir('MyBirdNetTest')\n",
        "    !git pull\n",
        "\n",
        "# Verify cloned repository\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzWY0D6D5Ipd",
        "outputId": "e4e8e38e-5497-40d7-c6f6-b93b5472650f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MyBirdNetTest/data/CSV_data\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/MyBirdNetTest/data/CSV_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJc9-abx4PzC",
        "outputId": "68c2abd2-8337-4897-c23f-aa6e134349c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "New Dataframe:\n",
            "   transect        date start_time end_time common_name     scientific_name  \\\n",
            "0         5  2024-05-02    4:00:21  4:00:24    Barn Owl           Tyto alba   \n",
            "1         5  2024-05-02    4:00:42  4:00:45     Mallard  Anas platyrhynchos   \n",
            "2         5  2024-05-02    4:00:48  4:00:51     Mallard  Anas platyrhynchos   \n",
            "3         5  2024-05-02    4:00:51  4:00:54     Mallard  Anas platyrhynchos   \n",
            "4         5  2024-05-02    4:01:36  4:01:39     Mallard  Anas platyrhynchos   \n",
            "\n",
            "   confidence                       label                 filename  \n",
            "0    0.259368          Tyto alba_Barn Owl  ED3_20240502_040000.wav  \n",
            "1    0.612938  Anas platyrhynchos_Mallard  ED3_20240502_040000.wav  \n",
            "2    0.509237  Anas platyrhynchos_Mallard  ED3_20240502_040000.wav  \n",
            "3    0.727033  Anas platyrhynchos_Mallard  ED3_20240502_040000.wav  \n",
            "4    0.262130  Anas platyrhynchos_Mallard  ED3_20240502_040000.wav  \n",
            "       transect        date start_time end_time          common_name  \\\n",
            "54392         8  2024-05-10    9:29:45  9:29:48   Common Wood-Pigeon   \n",
            "54393         8  2024-05-10    9:29:48  9:29:51   Common Wood-Pigeon   \n",
            "54394         8  2024-05-10    9:29:51  9:29:54    Common Chiffchaff   \n",
            "54395         8  2024-05-10    9:29:54  9:29:57  European Greenfinch   \n",
            "54396         8  2024-05-10    9:29:57  9:30:00   Common Wood-Pigeon   \n",
            "\n",
            "              scientific_name  confidence  \\\n",
            "54392        Columba palumbus    0.578695   \n",
            "54393        Columba palumbus    0.871840   \n",
            "54394  Phylloscopus collybita    0.331374   \n",
            "54395         Chloris chloris    0.604342   \n",
            "54396        Columba palumbus    0.421930   \n",
            "\n",
            "                                          label                 filename  \n",
            "54392       Columba palumbus_Common Wood-Pigeon  ED2_20240510_090000.wav  \n",
            "54393       Columba palumbus_Common Wood-Pigeon  ED2_20240510_090000.wav  \n",
            "54394  Phylloscopus collybita_Common Chiffchaff  ED2_20240510_090000.wav  \n",
            "54395       Chloris chloris_European Greenfinch  ED2_20240510_090000.wav  \n",
            "54396       Columba palumbus_Common Wood-Pigeon  ED2_20240510_090000.wav  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read in the CSV files\n",
        "df5 = pd.read_csv('BirdNET_results5.csv')\n",
        "df6 = pd.read_csv('BirdNET_results6.csv')\n",
        "df7 = pd.read_csv('BirdNET_results7.csv')\n",
        "df8 = pd.read_csv('BirdNET_results8.csv')\n",
        "\n",
        "# Add a column to each dataframe to indicate the transect source\n",
        "df5['transect'] = 5\n",
        "df6['transect'] = 6\n",
        "df7['transect'] = 7\n",
        "df8['transect'] = 8\n",
        "\n",
        "# Function to extract date and hour from the filename\n",
        "def extract_datetime(filename):\n",
        "    date_str = filename.split('_')[1]\n",
        "    time_str = filename.split('_')[2].split('.')[0]\n",
        "    datetime_str = date_str + ' ' + time_str\n",
        "    datetime = pd.to_datetime(datetime_str, format='%Y%m%d %H%M%S')\n",
        "    return datetime\n",
        "\n",
        "# Apply the function to create a new datetime column\n",
        "df5['datetime'] = df5['filename'].apply(extract_datetime)\n",
        "df6['datetime'] = df6['filename'].apply(extract_datetime)\n",
        "df7['datetime'] = df7['filename'].apply(extract_datetime)\n",
        "df8['datetime'] = df8['filename'].apply(extract_datetime)\n",
        "\n",
        "# Function to convert seconds to hour:minutes:seconds format based on the datetime\n",
        "def seconds_to_hms(datetime, seconds):\n",
        "    new_time = datetime + pd.to_timedelta(seconds, unit='s')\n",
        "    return new_time.strftime('%-H:%M:%S')\n",
        "\n",
        "# Apply the function to convert start_time and end_time\n",
        "df5['start_time'] = df5.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df5['end_time'] = df5.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "df6['start_time'] = df6.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df6['end_time'] = df6.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "df7['start_time'] = df7.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df7['end_time'] = df7.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "df8['start_time'] = df8.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df8['end_time'] = df8.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "concatenated_df = pd.concat([df5, df6, df7, df8], ignore_index=True)\n",
        "\n",
        "# Extract date\n",
        "concatenated_df['date'] = concatenated_df['datetime'].dt.date\n",
        "\n",
        "# Sort the dataframe by transect, date, start_time_readable, common_name, and confidence\n",
        "concatenated_df = concatenated_df.sort_values(by=['transect', 'date', 'start_time', 'common_name', 'confidence'])\n",
        "\n",
        "# Reorder the columns to have transect, date, time, and readable start/end times\n",
        "reordered_columns = ['transect', 'date', 'start_time', 'end_time', 'common_name', 'scientific_name', 'confidence', 'label', 'filename']\n",
        "concatenated_df = concatenated_df[reordered_columns]\n",
        "\n",
        "# Display the first few rows of the concatenated dataframe\n",
        "print(\"\\nNew Dataframe:\")\n",
        "print(concatenated_df.head())\n",
        "print(concatenated_df.tail())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tjslJO05ULN",
        "outputId": "58175c6b-cf15-4a7b-bb07-c2afa487830d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The combined dataframe has been saved to combined.csv\n"
          ]
        }
      ],
      "source": [
        "# Save the concatenated dataframe to a CSV file\n",
        "output_filename = 'combined.csv'\n",
        "concatenated_df.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"The combined dataframe has been saved to {output_filename}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNHbVq1sPmpS5NI2UJt3ajh",
      "include_colab_link": true,
      "mount_file_id": "1Pu-q_DeL88apaDeLRmkn_N18f4OaPsBX",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
