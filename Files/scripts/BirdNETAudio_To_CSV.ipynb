{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9rmWVVVcmVtjmQyTK9hDK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jamess200/BirdnetProject/blob/main/Files/scripts/BirdNETAudio_To_CSV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3uptz4Nqo-N",
        "outputId": "9a81318d-e3d1-45db-d04e-f47f70daacc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount Google Drive\n",
        "# Mount Google Drive to access files stored in it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Change Directory\n",
        "# Change the working directory to a specific path in your Google Drive\n",
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9fa0iu4qy-z",
        "outputId": "542f3dc3-49c1-47a4-ac6e-49648631da08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set Up Repository Path & Clone Repository\n",
        "import os\n",
        "# Define path in Google Drive where you want to clone the repository\n",
        "repo_path = '/content/drive/MyDrive/'\n",
        "\n",
        "# Check if directory already exists, create it if not\n",
        "if not os.path.exists(repo_path):\n",
        "    os.makedirs(repo_path)\n",
        "\n",
        "# Change working directory to defined path\n",
        "os.chdir(repo_path)\n",
        "\n",
        "# Clone the repository if doesnt exist, otherwise pull latest changes\n",
        "if not os.path.exists(os.path.join(repo_path, 'BirdnetProject')):\n",
        "    !git clone https://github.com/Jamess200/BirdnetProject\n",
        "else:\n",
        "    os.chdir('BirdnetProject')\n",
        "    !git pull\n",
        "\n",
        "# Verify cloned repository\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yQnVYMoq7Lz",
        "outputId": "2e49d21c-1a9e-4b9c-ce2b-60c70c87ab58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/27)\u001b[K\rremote: Counting objects:   7% (2/27)\u001b[K\rremote: Counting objects:  11% (3/27)\u001b[K\rremote: Counting objects:  14% (4/27)\u001b[K\rremote: Counting objects:  18% (5/27)\u001b[K\rremote: Counting objects:  22% (6/27)\u001b[K\rremote: Counting objects:  25% (7/27)\u001b[K\rremote: Counting objects:  29% (8/27)\u001b[K\rremote: Counting objects:  33% (9/27)\u001b[K\rremote: Counting objects:  37% (10/27)\u001b[K\rremote: Counting objects:  40% (11/27)\u001b[K\rremote: Counting objects:  44% (12/27)\u001b[K\rremote: Counting objects:  48% (13/27)\u001b[K\rremote: Counting objects:  51% (14/27)\u001b[K\rremote: Counting objects:  55% (15/27)\u001b[K\rremote: Counting objects:  59% (16/27)\u001b[K\rremote: Counting objects:  62% (17/27)\u001b[K\rremote: Counting objects:  66% (18/27)\u001b[K\rremote: Counting objects:  70% (19/27)\u001b[K\rremote: Counting objects:  74% (20/27)\u001b[K\rremote: Counting objects:  77% (21/27)\u001b[K\rremote: Counting objects:  81% (22/27)\u001b[K\rremote: Counting objects:  85% (23/27)\u001b[K\rremote: Counting objects:  88% (24/27)\u001b[K\rremote: Counting objects:  92% (25/27)\u001b[K\rremote: Counting objects:  96% (26/27)\u001b[K\rremote: Counting objects: 100% (27/27)\u001b[K\rremote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 22 (delta 11), reused 1 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (22/22), 689.33 KiB | 281.00 KiB/s, done.\n",
            "From https://github.com/Jamess200/BirdnetProject\n",
            "   4e10576..c54763d  main       -> origin/main\n",
            "Updating 1e003d5..c54763d\n",
            "error: Your local changes to the following files would be overwritten by merge:\n",
            "\tFiles/data/CSV_data/XC/XC_25_Merged.xlsx\n",
            "Please commit your changes or stash them before you merge.\n",
            "Aborting\n",
            "Files  Lost_Data_Prediction.ipynb  Main_AI_Human.ipynb\tREADME.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Required Python Packages\n",
        "# Install required packages\n",
        "!pip3 install birdnetlib\n",
        "!pip3 install tflite-runtime\n",
        "!pip3 install resampy\n",
        "!pip3 install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7NPCQIdq99k",
        "outputId": "ce008c67-845f-4b3c-a14b-b45b59a0688a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting birdnetlib\n",
            "  Downloading birdnetlib-0.17.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.10/dist-packages (from birdnetlib) (3.7.1)\n",
            "Collecting pydub==0.25.1 (from birdnetlib)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: requests>=2.28.1 in /usr/local/lib/python3.10/dist-packages (from birdnetlib) (2.32.3)\n",
            "Collecting watchdog==2.1.9 (from birdnetlib)\n",
            "  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28.1->birdnetlib) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28.1->birdnetlib) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28.1->birdnetlib) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28.1->birdnetlib) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.3->birdnetlib) (1.16.0)\n",
            "Downloading birdnetlib-0.17.2-py3-none-any.whl (61.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, watchdog, birdnetlib\n",
            "Successfully installed birdnetlib-0.17.2 pydub-0.25.1 watchdog-2.1.9\n",
            "Collecting tflite-runtime\n",
            "  Downloading tflite_runtime-2.14.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.10/dist-packages (from tflite-runtime) (1.26.4)\n",
            "Downloading tflite_runtime-2.14.0-cp310-cp310-manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tflite-runtime\n",
            "Successfully installed tflite-runtime-2.14.0\n",
            "Collecting resampy\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.26.4)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.43.0)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: resampy\n",
            "Successfully installed resampy-0.4.3\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=8a20dc3a9e5f17956597059c776c92549d76e368cdd75b31a5ebcdfb1492eaf1\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Necessary Libraries\n",
        "# Import necessary libraries\n",
        "import resampy\n",
        "import birdnetlib\n",
        "import tflite_runtime\n",
        "import ffmpeg\n",
        "import pandas as pd\n",
        "from birdnetlib import Recording\n",
        "from birdnetlib.analyzer import Analyzer\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "llAeWFuFrFo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set Up Directory and File Paths\n",
        "# Define the directory where the data is stored\n",
        "dataDir = '/content/drive/MyDrive/HAUtrans/Trans5/'\n",
        "\n",
        "# List all files in the directory\n",
        "file_names = os.listdir(dataDir)\n",
        "\n",
        "# Print the file names to verify the data files\n",
        "print(file_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBRL8TiQrGdK",
        "outputId": "4a856687-b1fe-48a0-f732-cb960d652c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ED3_20240502_040000.wav', 'ED3_20240502_050000.wav', 'ED3_20240502_060000.wav', 'ED3_20240502_070000.wav', 'ED3_20240502_080000.wav', 'ED3_20240502_090000.wav', 'ED3_20240503_040000.wav', 'ED3_20240503_050000.wav', 'ED3_20240503_060000.wav', 'ED3_20240503_070000.wav', 'ED3_20240503_080000.wav', 'ED3_20240503_090000.wav', 'ED3_20240504_040000.wav', 'ED3_20240504_050000.wav', 'ED3_20240504_060000.wav', 'ED3_20240504_070000.wav', 'ED3_20240504_080000.wav', 'ED3_20240504_090000.wav', 'ED3_20240505_040000.wav', 'ED3_20240505_050000.wav', 'ED3_20240505_060000.wav', 'ED3_20240505_070000.wav', 'ED3_20240505_080000.wav', 'ED3_20240505_090000.wav', 'ED3_20240506_040000.wav', 'ED3_20240506_050000.wav', 'ED3_20240506_060000.wav', 'ED3_20240506_070000.wav', 'ED3_20240506_080000.wav', 'ED3_20240506_090000.wav', 'ED3_20240507_040000.wav', 'ED3_20240507_050000.wav', 'ED3_20240507_060000.wav', 'ED3_20240507_070000.wav', 'ED3_20240507_080000.wav', 'ED3_20240507_090000.wav', 'ED3_20240508_040000.wav', 'ED3_20240508_050000.wav', 'ED3_20240508_060000.wav', 'ED3_20240508_070000.wav', 'ED3_20240508_080000.wav', 'ED3_20240508_090000.wav', 'ED3_20240509_040000.wav', 'ED3_20240509_050000.wav', 'ED3_20240509_060000.wav', 'ED3_20240509_070000.wav', 'ED3_20240509_080000.wav', 'ED3_20240509_090000.wav', 'ED3_20240510_040000.wav', 'ED3_20240510_050000.wav', 'ED3_20240510_060000.wav', 'ED3_20240510_070000.wav', 'ED3_20240510_080000.wav', 'ED3_20240510_090000.wav']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialise BirdNET Analyzer\n",
        "# Initialise the BirdNET-Analyzer model\n",
        "analyzer = Analyzer()\n",
        "# Define the coordinates and date for the recordings\n",
        "testamp = [52.911,-2.4441] # near Market Drayton year=2024, month=4, day=20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn-FEzj3rLgm",
        "outputId": "22ca5d51-78dc-4386-8d51-dc136f8b0de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels loaded.\n",
            "load model True\n",
            "Model loaded.\n",
            "Labels loaded.\n",
            "load_species_list_model\n",
            "Meta model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Analyse Audio Files and Store Results\n",
        "# Create a dictionary to store the results\n",
        "results = {}\n",
        "# Loop through all file names\n",
        "for file_name in file_names:\n",
        "    try:\n",
        "      # Include the correct path to the data files\n",
        "      file_path = os.path.join(dataDir, file_name)\n",
        "      recording = Recording(\n",
        "          analyzer,\n",
        "          file_path,  # path to the recording file\n",
        "          lat=testamp[0], # latitude of the recording location\n",
        "          lon=testamp[1], # longitude of the recording location\n",
        "          date=datetime(year=2024, month=4, day=20), # use date or week_48\n",
        "          min_conf=0.25,\n",
        "      )\n",
        "      # Analyse the recording and store the result in the dictionary\n",
        "      recording.analyze()\n",
        "      results[file_name] = recording.detections\n",
        "    except Exception as e:\n",
        "      print(f\"Error processing {file_name}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "2UfnSVKurQGO",
        "outputId": "568c1c64-4696-47ae-f648-b86386a86992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "read_audio_data\n",
            "read_audio_data: complete, read  600 chunks.\n",
            "analyze_recording ED3_20240502_040000.wav\n",
            "recording has lon/lat\n",
            "set_predicted_species_list_from_position\n",
            "return_predicted_species_list\n",
            "15\n",
            "145 species loaded.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4abd112bd106>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m       )\n\u001b[1;32m     17\u001b[0m       \u001b[0;31m# Analyse the recording and store the result in the dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mrecording\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecording\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/birdnetlib/main.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Read and analyze.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_audio_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/birdnetlib/analyzer.py\u001b[0m in \u001b[0;36manalyze_recording\u001b[0;34m(self, recording)\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_with_custom_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;31m# Assign scores to labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/birdnetlib/analyzer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         )\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tflite_runtime/interpreter.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m     \"\"\"\n\u001b[1;32m    940\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert Results to DataFrame and Save as CSV\n",
        "# Flatten the results dictionary\n",
        "flattened_data = []\n",
        "for filename, records in results.items():\n",
        "    for record in records:\n",
        "        record['filename'] = filename\n",
        "        flattened_data.append(record)\n",
        "\n",
        "# Convert the flattened data to a DataFrame\n",
        "df = pd.DataFrame(flattened_data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_file_path = '/content/drive/MyDrive/BirdnetProject/Files/data/CSV_data/transect_5.csv'\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "# Confirm that the results have been saved successfully\n",
        "print(f\"Results have been successfully converted to CSV and saved to {csv_file_path}\")"
      ],
      "metadata": {
        "id": "p3gTAkY3rVAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load and Verify CSV Data\n",
        "# Load the saved CSV file into a DataFrame to verify the contents\n",
        "csv_file_path = '/content/drive/MyDrive/BirdnetProject/Files/data/CSV_data/transect_5.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Print the DataFrame to verify the data\n",
        "print(df.head)"
      ],
      "metadata": {
        "id": "B_WE42nZrcH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Change Working Directory\n",
        "# Change working directory to defined path\n",
        "os.chdir('/content/drive/MyDrive/BirdnetProject/Files/data/CSV_data')\n",
        "\n",
        "# Verify working directory\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "v_4RGQ4Qr7w4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Merged Dataframe File For All Transects\n",
        "import pandas as pd\n",
        "\n",
        "# Read in the CSV files\n",
        "df5 = pd.read_csv('transect_5.csv')\n",
        "df6 = pd.read_csv('transect_6.csv')\n",
        "df7 = pd.read_csv('transect_7.csv')\n",
        "df8 = pd.read_csv('transect_8.csv')\n",
        "\n",
        "# Add a column to each dataframe to indicate the transect source\n",
        "df5['transect'] = 5\n",
        "df6['transect'] = 6\n",
        "df7['transect'] = 7\n",
        "df8['transect'] = 8\n",
        "\n",
        "# Function to extract date and hour from the filename\n",
        "def extract_datetime(filename):\n",
        "    date_str = filename.split('_')[1]\n",
        "    time_str = filename.split('_')[2].split('.')[0]\n",
        "    datetime_str = date_str + ' ' + time_str\n",
        "    datetime = pd.to_datetime(datetime_str, format='%Y%m%d %H%M%S')\n",
        "    return datetime\n",
        "\n",
        "# Apply the function to create a new datetime column\n",
        "df5['datetime'] = df5['filename'].apply(extract_datetime)\n",
        "df6['datetime'] = df6['filename'].apply(extract_datetime)\n",
        "df7['datetime'] = df7['filename'].apply(extract_datetime)\n",
        "df8['datetime'] = df8['filename'].apply(extract_datetime)\n",
        "\n",
        "# Function to convert seconds to hour:minutes:seconds format based on the datetime\n",
        "def seconds_to_hms(datetime, seconds):\n",
        "    new_time = datetime + pd.to_timedelta(seconds, unit='s')\n",
        "    return new_time.strftime('%-H:%M:%S')\n",
        "\n",
        "# Apply the function to convert start_time and end_time\n",
        "df5['start_time'] = df5.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df5['end_time'] = df5.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "df6['start_time'] = df6.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df6['end_time'] = df6.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "df7['start_time'] = df7.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df7['end_time'] = df7.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "df8['start_time'] = df8.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df8['end_time'] = df8.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "concatenated_df = pd.concat([df5, df6, df7, df8], ignore_index=True)\n",
        "\n",
        "# Extract date and start hour\n",
        "concatenated_df['date'] = concatenated_df['datetime'].dt.date\n",
        "concatenated_df['start_hour'] = concatenated_df['datetime'].dt.hour\n",
        "\n",
        "# Sort the dataframe by transect, date, start_time, common_name, and confidence\n",
        "concatenated_df = concatenated_df.sort_values(by=['transect', 'date', 'start_time', 'common_name', 'confidence'])\n",
        "\n",
        "# Reorder the columns to have transect, date, start_hour, time, and readable start/end times\n",
        "reordered_columns = ['transect', 'date', 'start_hour', 'start_time', 'end_time', 'common_name', 'scientific_name', 'confidence', 'label', 'filename']\n",
        "concatenated_df = concatenated_df[reordered_columns]\n",
        "\n",
        "# Display the first few rows of the concatenated dataframe\n",
        "print(\"\\nNew Dataframe:\")\n",
        "print(concatenated_df.head())\n",
        "print(concatenated_df.tail())\n"
      ],
      "metadata": {
        "id": "bfsDuMwgsAbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save data as a CSV File\n",
        "# Save the concatenated dataframe to a CSV file\n",
        "output_filename = 'transect_combined.csv'\n",
        "concatenated_df.to_csv(output_filename, index=False)\n",
        "print(f\"The combined dataframe has been saved to {output_filename}\")"
      ],
      "metadata": {
        "id": "THEz2_7bsGcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save Data as a Excel File\n",
        "# Save the dataframe to an Excel file\n",
        "output_file = 'Bird_Detection_Data.xlsx'\n",
        "concatenated_df.to_excel(output_file, index=False)\n",
        "print(f\"\\nDataframe has been saved to {output_file}\")"
      ],
      "metadata": {
        "id": "5ZcgtPULsIE3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}