{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jamess200/BirdnetProject/blob/main/Files/scripts/merge_csv_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tbKUemG3l9p",
        "outputId": "3200641e-e7eb-4c6c-e33e-f140bf5a26b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#@title Mount Google Drive\n",
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKqvX2HR2zC-",
        "outputId": "3b486def-0966-4e1a-a850-8ccbc2bcf9a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/18)\u001b[K\rremote: Counting objects:  11% (2/18)\u001b[K\rremote: Counting objects:  16% (3/18)\u001b[K\rremote: Counting objects:  22% (4/18)\u001b[K\rremote: Counting objects:  27% (5/18)\u001b[K\rremote: Counting objects:  33% (6/18)\u001b[K\rremote: Counting objects:  38% (7/18)\u001b[K\rremote: Counting objects:  44% (8/18)\u001b[K\rremote: Counting objects:  50% (9/18)\u001b[K\rremote: Counting objects:  55% (10/18)\u001b[K\rremote: Counting objects:  61% (11/18)\u001b[K\rremote: Counting objects:  66% (12/18)\u001b[K\rremote: Counting objects:  72% (13/18)\u001b[K\rremote: Counting objects:  77% (14/18)\u001b[K\rremote: Counting objects:  83% (15/18)\u001b[K\rremote: Counting objects:  88% (16/18)\u001b[K\rremote: Counting objects:  94% (17/18)\u001b[K\rremote: Counting objects: 100% (18/18)\u001b[K\rremote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 12 (delta 5), reused 8 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (12/12), 3.33 MiB | 857.00 KiB/s, done.\n",
            "From https://github.com/Jamess200/MyBirdNetTest\n",
            "   05d294c..5e85fa1  main       -> origin/main\n",
            "Updating 05d294c..5e85fa1\n",
            "error: Your local changes to the following files would be overwritten by merge:\n",
            "\tFiles/data/CSV_data/transect_combined.csv\n",
            "Please commit your changes or stash them before you merge.\n",
            "Aborting\n",
            "Files  README.md\n"
          ]
        }
      ],
      "source": [
        "#@title Clone Repo\n",
        "import os\n",
        "\n",
        "# Define path in Google Drive where you want to clone the repository\n",
        "repo_path = '/content/drive/MyDrive/'\n",
        "\n",
        "# Check if directory already exists\n",
        "if not os.path.exists(repo_path):\n",
        "    os.makedirs(repo_path)\n",
        "\n",
        "# Change working directory to defined path\n",
        "os.chdir(repo_path)\n",
        "\n",
        "# Clone the repository if doesnt exist, otherwise pull latest changes\n",
        "if not os.path.exists(os.path.join(repo_path, 'MyBirdNetTest')):\n",
        "    !git clone https://github.com/Jamess200/MyBirdNetTest.git\n",
        "else:\n",
        "    os.chdir('MyBirdNetTest')\n",
        "    !git pull\n",
        "\n",
        "# Verify cloned repository\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzWY0D6D5Ipd",
        "outputId": "89e9180e-fed1-453c-f8ef-7e2a7d1d5e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MyBirdNetTest/Files/data/CSV_data\n"
          ]
        }
      ],
      "source": [
        "#@title Change Working Directory\n",
        "# Change working directory to defined path\n",
        "os.chdir('/content/drive/MyDrive/MyBirdNetTest/Files/data/CSV_data')\n",
        "\n",
        "# Verify working directory\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJc9-abx4PzC",
        "outputId": "cf19846c-1c0e-417e-bd91-2ad8e1bb7df9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New Dataframe:\n",
            "   transect        date  start_hour start_time end_time common_name  \\\n",
            "0         5  2024-05-02           4    4:00:21  4:00:24    Barn Owl   \n",
            "1         5  2024-05-02           4    4:00:42  4:00:45     Mallard   \n",
            "2         5  2024-05-02           4    4:00:48  4:00:51     Mallard   \n",
            "3         5  2024-05-02           4    4:00:51  4:00:54     Mallard   \n",
            "4         5  2024-05-02           4    4:01:36  4:01:39     Mallard   \n",
            "\n",
            "      scientific_name  confidence                       label  \\\n",
            "0           Tyto alba    0.259368          Tyto alba_Barn Owl   \n",
            "1  Anas platyrhynchos    0.612938  Anas platyrhynchos_Mallard   \n",
            "2  Anas platyrhynchos    0.509237  Anas platyrhynchos_Mallard   \n",
            "3  Anas platyrhynchos    0.727033  Anas platyrhynchos_Mallard   \n",
            "4  Anas platyrhynchos    0.262130  Anas platyrhynchos_Mallard   \n",
            "\n",
            "                  filename  \n",
            "0  ED3_20240502_040000.wav  \n",
            "1  ED3_20240502_040000.wav  \n",
            "2  ED3_20240502_040000.wav  \n",
            "3  ED3_20240502_040000.wav  \n",
            "4  ED3_20240502_040000.wav  \n",
            "       transect        date  start_hour start_time end_time  \\\n",
            "54392         8  2024-05-10           9    9:29:45  9:29:48   \n",
            "54393         8  2024-05-10           9    9:29:48  9:29:51   \n",
            "54394         8  2024-05-10           9    9:29:51  9:29:54   \n",
            "54395         8  2024-05-10           9    9:29:54  9:29:57   \n",
            "54396         8  2024-05-10           9    9:29:57  9:30:00   \n",
            "\n",
            "               common_name         scientific_name  confidence  \\\n",
            "54392   Common Wood-Pigeon        Columba palumbus    0.578695   \n",
            "54393   Common Wood-Pigeon        Columba palumbus    0.871840   \n",
            "54394    Common Chiffchaff  Phylloscopus collybita    0.331374   \n",
            "54395  European Greenfinch         Chloris chloris    0.604342   \n",
            "54396   Common Wood-Pigeon        Columba palumbus    0.421930   \n",
            "\n",
            "                                          label                 filename  \n",
            "54392       Columba palumbus_Common Wood-Pigeon  ED2_20240510_090000.wav  \n",
            "54393       Columba palumbus_Common Wood-Pigeon  ED2_20240510_090000.wav  \n",
            "54394  Phylloscopus collybita_Common Chiffchaff  ED2_20240510_090000.wav  \n",
            "54395       Chloris chloris_European Greenfinch  ED2_20240510_090000.wav  \n",
            "54396       Columba palumbus_Common Wood-Pigeon  ED2_20240510_090000.wav  \n"
          ]
        }
      ],
      "source": [
        "#@title Create Merged Dataframe File For All Transects\n",
        "import pandas as pd\n",
        "\n",
        "# Read in the CSV files\n",
        "df5 = pd.read_csv('transect_5.csv')\n",
        "df6 = pd.read_csv('transect_6.csv')\n",
        "df7 = pd.read_csv('transect_7.csv')\n",
        "df8 = pd.read_csv('transect_8.csv')\n",
        "\n",
        "# Add a column to each dataframe to indicate the transect source\n",
        "df5['transect'] = 5\n",
        "df6['transect'] = 6\n",
        "df7['transect'] = 7\n",
        "df8['transect'] = 8\n",
        "\n",
        "# Function to extract date and hour from the filename\n",
        "def extract_datetime(filename):\n",
        "    date_str = filename.split('_')[1]\n",
        "    time_str = filename.split('_')[2].split('.')[0]\n",
        "    datetime_str = date_str + ' ' + time_str\n",
        "    datetime = pd.to_datetime(datetime_str, format='%Y%m%d %H%M%S')\n",
        "    return datetime\n",
        "\n",
        "# Apply the function to create a new datetime column\n",
        "df5['datetime'] = df5['filename'].apply(extract_datetime)\n",
        "df6['datetime'] = df6['filename'].apply(extract_datetime)\n",
        "df7['datetime'] = df7['filename'].apply(extract_datetime)\n",
        "df8['datetime'] = df8['filename'].apply(extract_datetime)\n",
        "\n",
        "# Function to convert seconds to hour:minutes:seconds format based on the datetime\n",
        "def seconds_to_hms(datetime, seconds):\n",
        "    new_time = datetime + pd.to_timedelta(seconds, unit='s')\n",
        "    return new_time.strftime('%-H:%M:%S')\n",
        "\n",
        "# Apply the function to convert start_time and end_time\n",
        "df5['start_time'] = df5.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df5['end_time'] = df5.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "df6['start_time'] = df6.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df6['end_time'] = df6.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "df7['start_time'] = df7.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df7['end_time'] = df7.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "df8['start_time'] = df8.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df8['end_time'] = df8.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "concatenated_df = pd.concat([df5, df6, df7, df8], ignore_index=True)\n",
        "\n",
        "# Extract date and start hour\n",
        "concatenated_df['date'] = concatenated_df['datetime'].dt.date\n",
        "concatenated_df['start_hour'] = concatenated_df['datetime'].dt.hour\n",
        "\n",
        "# Sort the dataframe by transect, date, start_time, common_name, and confidence\n",
        "concatenated_df = concatenated_df.sort_values(by=['transect', 'date', 'start_time', 'common_name', 'confidence'])\n",
        "\n",
        "# Reorder the columns to have transect, date, start_hour, time, and readable start/end times\n",
        "reordered_columns = ['transect', 'date', 'start_hour', 'start_time', 'end_time', 'common_name', 'scientific_name', 'confidence', 'label', 'filename']\n",
        "concatenated_df = concatenated_df[reordered_columns]\n",
        "\n",
        "# Display the first few rows of the concatenated dataframe\n",
        "print(\"\\nNew Dataframe:\")\n",
        "print(concatenated_df.head())\n",
        "print(concatenated_df.tail())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tjslJO05ULN",
        "outputId": "1eadf9ef-60e2-4d99-b0d0-445d2b4cd439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The combined dataframe has been saved to transect_combined.csv\n"
          ]
        }
      ],
      "source": [
        "#@title Save data as a CSV File\n",
        "# Save the concatenated dataframe to a CSV file\n",
        "output_filename = 'transect_combined.csv'\n",
        "concatenated_df.to_csv(output_filename, index=False)\n",
        "print(f\"The combined dataframe has been saved to {output_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save Data as a Excel File\n",
        "# Save the dataframe to an Excel file\n",
        "output_file = 'Bird_Detection_Data.xlsx'\n",
        "concatenated_df.to_excel(output_file, index=False)\n",
        "print(f\"\\nDataframe has been saved to {output_file}\")"
      ],
      "metadata": {
        "id": "vhURL6ewyyz_",
        "outputId": "7c2e222f-50fd-4e5d-aafc-b1dd1a4b5db5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataframe has been saved to Bird_Detection_Data.xlsx\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}