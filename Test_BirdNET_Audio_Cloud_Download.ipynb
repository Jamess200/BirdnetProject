{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbnWKsxXzrkWx/OxCwglt3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jamess200/BirdnetProject/blob/main/Test_BirdNET_Audio_Cloud_Download.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **<------------ Part 1 ------------>**"
      ],
      "metadata": {
        "id": "IhO7E-UHdg6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Testing Alternative Method for Audio Processing and CSV Creation**\n",
        "# This notebook guides you through analysing bird audio recordings using BirdNET."
      ],
      "metadata": {
        "id": "VEu9kipAphQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 1: Install & Import Required Libraries**\n",
        "# Install PyDrive to download files from Google Drive, and other packages for processing.\n",
        "!pip install PyDrive birdnetlib tflite-runtime resampy ffmpeg pygbif mplcursors\n",
        "\n",
        "# Import necessary libraries for BirdNET\n",
        "import resampy\n",
        "import birdnetlib\n",
        "import tflite_runtime\n",
        "import ffmpeg\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import mplcursors\n",
        "import os\n",
        "import re\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from birdnetlib import Recording\n",
        "from birdnetlib.analyzer import Analyzer\n",
        "from datetime import datetime\n",
        "from pygbif import occurrences\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6STr5lGE9sFd",
        "outputId": "08e98a4e-99d5-405d-aa8d-d7972d9c389f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Collecting birdnetlib\n",
            "  Downloading birdnetlib-0.17.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting tflite-runtime\n",
            "  Downloading tflite_runtime-2.14.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting resampy\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygbif\n",
            "  Downloading pygbif-0.6.4-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mplcursors\n",
            "  Downloading mplcursors-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.10/dist-packages (from PyDrive) (2.137.0)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.10/dist-packages (from PyDrive) (6.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.10/dist-packages (from birdnetlib) (3.7.1)\n",
            "Collecting pydub==0.25.1 (from birdnetlib)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: requests>=2.28.1 in /usr/local/lib/python3.10/dist-packages (from birdnetlib) (2.32.3)\n",
            "Collecting watchdog==2.1.9 (from birdnetlib)\n",
            "  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.10/dist-packages (from tflite-runtime) (1.26.4)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.60.0)\n",
            "Collecting requests-cache (from pygbif)\n",
            "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting geojson-rewind (from pygbif)\n",
            "  Downloading geojson_rewind-1.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting geomet (from pygbif)\n",
            "  Downloading geomet-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting appdirs>=1.4.3 (from pygbif)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting matplotlib>=3.5.3 (from birdnetlib)\n",
            "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (2.19.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (4.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.3->birdnetlib) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.43.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28.1->birdnetlib) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28.1->birdnetlib) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28.1->birdnetlib) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28.1->birdnetlib) (2024.7.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet->pygbif) (8.1.7)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache->pygbif) (24.2.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache->pygbif)\n",
            "  Downloading cattrs-24.1.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-cache->pygbif) (4.2.2)\n",
            "Collecting url-normalize>=1.4 (from requests-cache->pygbif)\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache->pygbif) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache->pygbif) (4.12.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (1.64.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (1.24.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.2->PyDrive) (5.5.0)\n",
            "Downloading birdnetlib-0.17.2-py3-none-any.whl (61.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tflite_runtime-2.14.0-cp310-cp310-manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygbif-0.6.4-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading geojson_rewind-1.1.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading geomet-1.1.0-py3-none-any.whl (31 kB)\n",
            "Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cattrs-24.1.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Building wheels for collected packages: ffmpeg, mplcursors\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=792d34b02c896db3ee484579043b48459d1bdd130c3e33a054fb26e9585ff97e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "  Building wheel for mplcursors (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mplcursors: filename=mplcursors-0.5.3-py3-none-any.whl size=20728 sha256=4c988a260b787ac044a56042aaabc8ae27b557617c85d9579c1d3a895d1cb257\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/43/92/44f9515471f56877c774a515a2902d3e5484ea1bc7fd412d03\n",
            "Successfully built ffmpeg mplcursors\n",
            "Installing collected packages: pydub, ffmpeg, appdirs, watchdog, url-normalize, tflite-runtime, geomet, geojson-rewind, cattrs, resampy, requests-cache, matplotlib, pygbif, mplcursors, birdnetlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "Successfully installed appdirs-1.4.4 birdnetlib-0.17.2 cattrs-24.1.0 ffmpeg-1.4 geojson-rewind-1.1.0 geomet-1.1.0 matplotlib-3.9.2 mplcursors-0.5.3 pydub-0.25.1 pygbif-0.6.4 requests-cache-1.2.1 resampy-0.4.3 tflite-runtime-2.14.0 url-normalize-1.4.3 watchdog-2.1.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 2: Clone the GitHub Repository**\n",
        "# This step clones the required GitHub repository into the Colab environment.\n",
        "\n",
        "# Define the path where the repository will be cloned\n",
        "repo_path = '/content/BirdnetProject'\n",
        "\n",
        "# Check if the repository already exists\n",
        "if not os.path.exists(repo_path):\n",
        "    # Clone the repository if it doesn't exist\n",
        "    !git clone https://github.com/Jamess200/BirdnetProject\n",
        "else:\n",
        "    # If the repository exists, pull the latest changes\n",
        "    os.chdir(repo_path)\n",
        "    !git pull\n",
        "\n",
        "# Verify cloned repository\n",
        "print(\"Repository contents:\")\n",
        "!ls /content/BirdnetProject"
      ],
      "metadata": {
        "id": "HWPTZH1VmiOD",
        "outputId": "ef72849a-5c67-44fe-8ad6-79246f1379d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BirdnetProject'...\n",
            "remote: Enumerating objects: 748, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 748 (delta 37), reused 5 (delta 4), pack-reused 682 (from 1)\u001b[K\n",
            "Receiving objects: 100% (748/748), 1.36 GiB | 20.07 MiB/s, done.\n",
            "Resolving deltas: 100% (351/351), done.\n",
            "Repository contents:\n",
            "Files  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 3: Authenticate and Create PyDrive Client**\n",
        "# This step authenticates with Google to access the shared folder on Google Drive.\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "print(\"Authentication successful. You can now access files from the shared Google Drive folder.\")"
      ],
      "metadata": {
        "id": "ib3Gj3iNWzF2",
        "outputId": "d26e0bf7-4130-4a0e-bc0d-a103f92f0220",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authentication successful. You can now access files from the shared Google Drive folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoUfTX4x9MPW"
      },
      "outputs": [],
      "source": [
        "#@title **Step 4: Define Helper Functions**\n",
        "# These functions help to download the test audio file from my Google Drive folder to a local directory and list files.\n",
        "\n",
        "def download_files_from_drive(folder_id, destination):\n",
        "    \"\"\"\n",
        "    Download all files from a Google Drive folder to a local directory.\n",
        "\n",
        "    :param folder_id: str, The ID of the Google Drive folder\n",
        "    :param destination: str, The local directory to save the files\n",
        "    \"\"\"\n",
        "    # List all files in the shared folder\n",
        "    file_list = drive.ListFile({'q': f\"'{folder_id}' in parents and trashed=false\"}).GetList()\n",
        "\n",
        "    # Create a directory to store the downloaded audio files\n",
        "    os.makedirs(destination, exist_ok=True)\n",
        "\n",
        "    # Download each file to the local directory\n",
        "    for file in file_list:\n",
        "        file_id = file['id']\n",
        "        file_name = file['title']\n",
        "        file_path = os.path.join(destination, file_name)\n",
        "        print(f\"Downloading {file_name}...\")\n",
        "        downloaded_file = drive.CreateFile({'id': file_id})\n",
        "        downloaded_file.GetContentFile(file_path)\n",
        "    print(\"All files downloaded successfully!\")\n",
        "\n",
        "def list_files_in_directory(directory):\n",
        "    \"\"\"\n",
        "    List all files in a directory and print their names.\n",
        "\n",
        "    :param directory: str, The directory to list files\n",
        "    \"\"\"\n",
        "    file_names = os.listdir(directory)\n",
        "    print(f\"Files in {directory}:\")\n",
        "    for file_name in file_names:\n",
        "        print(file_name)\n",
        "    return file_names"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 5: Download Audio Files from Google Drive**\n",
        "# This step will download all audio files from the shared Google Drive folder to the local directory.\n",
        "\n",
        "# Replace the folder ID with your shared folder's ID\n",
        "folder_id = '1PAkwwWpQY5Y8vgvkmVYm5Z_oKBVfr3e_'  # Update this with your folder ID\n",
        "dataDir = '/content/audio_files'\n",
        "\n",
        "# Download files from Google Drive\n",
        "download_files_from_drive(folder_id, dataDir)\n",
        "\n",
        "# List all files in the directory to verify download\n",
        "file_names = list_files_in_directory(dataDir)"
      ],
      "metadata": {
        "id": "ue-RsKMmISyR",
        "outputId": "2f3405f6-30ca-47f2-addc-247ff7754a34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading XC3_20210404_054400.mp3...\n",
            "All files downloaded successfully!\n",
            "Files in /content/audio_files:\n",
            "XC3_20210404_054400.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 6: Initialise BirdNET Analyzer and Process Audio Files**\n",
        "# This step initialises the BirdNET-Analyzer model and processes the downloaded audio files.\n",
        "# Initialise BirdNET-Analyzer model\n",
        "analyzer = Analyzer()\n",
        "\n",
        "# Define the coordinates and date for the recordings\n",
        "coordinates = [51.7813, -2.5745]  # Replace with your coordinates (Latitude, Longitude)\n",
        "recording_date = datetime(year=2021, month=4, day=4)\n",
        "\n",
        "# Analyse Audio Files and Store Results\n",
        "results = {}\n",
        "\n",
        "for file_name in file_names:\n",
        "    try:\n",
        "        file_path = os.path.join(dataDir, file_name)\n",
        "\n",
        "        # Skip directories\n",
        "        if os.path.isdir(file_path):\n",
        "            continue\n",
        "\n",
        "        # Skip non-audio files\n",
        "        if not file_name.lower().endswith(('.wav', '.mp3', '.flac')):\n",
        "            print(f\"Skipping non-audio file: {file_name}\")\n",
        "            continue\n",
        "\n",
        "        # Initialise a Recording object\n",
        "        recording = Recording(\n",
        "            analyzer,\n",
        "            file_path,  # path to the recording file\n",
        "            lat=coordinates[0],  # latitude of the recording location\n",
        "            lon=coordinates[1],  # longitude of the recording location\n",
        "            date=recording_date,  # the date of the recording\n",
        "            min_conf=0.1,  # Set Minimum Confidence\n",
        "        )\n",
        "\n",
        "        # Analyze the recording\n",
        "        recording.analyze()\n",
        "\n",
        "        # Store the results\n",
        "        results[file_name] = recording.detections\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_name}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ke3hNq79dxN",
        "outputId": "62a501dc-695c-42f3-955a-86bca3282683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels loaded.\n",
            "load model True\n",
            "Model loaded.\n",
            "Labels loaded.\n",
            "load_species_list_model\n",
            "Meta model loaded.\n",
            "read_audio_data\n",
            "read_audio_data: complete, read  1464 chunks.\n",
            "analyze_recording XC3_20210404_054400.mp3\n",
            "recording has lon/lat\n",
            "set_predicted_species_list_from_position\n",
            "return_predicted_species_list\n",
            "13\n",
            "141 species loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 7: Convert Results to DataFrame and Save as CSV**\n",
        "# Flatten the results dictionary and convert it to a DataFrame. Save the DataFrame as a CSV file.\n",
        "\n",
        "flattened_data = []\n",
        "for filename, records in results.items():\n",
        "    for record in records:\n",
        "        record['filename'] = filename\n",
        "        flattened_data.append(record)\n",
        "\n",
        "# Convert the flattened data to a DataFrame\n",
        "df = pd.DataFrame(flattened_data)\n",
        "\n",
        "# Define the path to save the CSV file\n",
        "csv_file_path = '/content/BirdnetProject/Files/data/CSV_data/XC/XC3_1_20210404_054400.csv'\n",
        "os.makedirs(os.path.dirname(csv_file_path), exist_ok=True)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"Results have been successfully converted to CSV and saved to {csv_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDJ6voT6KQ8k",
        "outputId": "01601dd8-f474-45a3-a60b-95d4e120b4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results have been successfully converted to CSV and saved to /content/BirdnetProject/Files/data/CSV_data/XC/XC3_1_20210404_054400.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLU34dwg2fR4",
        "outputId": "8ae1908c-2475-453c-d608-eb3bcf00007a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            common_name      scientific_name  start_time  end_time  \\\n",
            "0        European Robin   Erithacus rubecula       195.0     198.0   \n",
            "1             Goldcrest      Regulus regulus       273.0     276.0   \n",
            "2      Common Firecrest  Regulus ignicapilla       423.0     426.0   \n",
            "3  Eurasian Treecreeper   Certhia familiaris       447.0     450.0   \n",
            "4    Common Wood-Pigeon     Columba palumbus       555.0     558.0   \n",
            "\n",
            "   confidence                                    label  \\\n",
            "0    0.103502        Erithacus rubecula_European Robin   \n",
            "1    0.175837                Regulus regulus_Goldcrest   \n",
            "2    0.103631     Regulus ignicapilla_Common Firecrest   \n",
            "3    0.271523  Certhia familiaris_Eurasian Treecreeper   \n",
            "4    0.110816      Columba palumbus_Common Wood-Pigeon   \n",
            "\n",
            "                  filename  \n",
            "0  XC3_20210404_054400.mp3  \n",
            "1  XC3_20210404_054400.mp3  \n",
            "2  XC3_20210404_054400.mp3  \n",
            "3  XC3_20210404_054400.mp3  \n",
            "4  XC3_20210404_054400.mp3  \n"
          ]
        }
      ],
      "source": [
        "#@title **Step 8: Load and Verify CSV Data**\n",
        "# Load the saved CSV file into a DataFrame to verify the contents\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Print the first few rows of the DataFrame to verify the data\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 9: Save CSV File to Desired Location**\n",
        "# This step allows users to save the CSV file to their desired location.\n",
        "\n",
        "# Ask the user where they want to save the CSV file\n",
        "save_option = input(\"Where would you like to save the CSV file? Enter 'local' to download to your device or 'drive' to save to Google Drive: \")\n",
        "\n",
        "if save_option.lower() == 'drive':\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_csv_path = input(\"Enter the path in your Google Drive where you want to save the CSV file (e.g., /content/drive/MyDrive/BirdnetProject/Files/data/CSV_data/): \")\n",
        "    drive_csv_path = os.path.join(drive_csv_path, os.path.basename(csv_file_path))\n",
        "    # Copy the file to Google Drive\n",
        "    !cp {csv_file_path} {drive_csv_path}\n",
        "    print(f\"CSV file saved to your Google Drive at {drive_csv_path}\")\n",
        "elif save_option.lower() == 'local':\n",
        "    # Download the file to the user's local device\n",
        "    files.download(csv_file_path)\n",
        "    print(\"CSV file downloaded to your local device.\")\n",
        "else:\n",
        "    print(\"Invalid option. Please enter 'local' or 'drive'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Wr3GNxvlQCUe",
        "outputId": "cbb5c334-0914-47ac-e80c-959d5a2df290"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Where would you like to save the CSV file? Enter 'local' to download to your device or 'drive' to save to Google Drive: local\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8d87c4ce-d92a-46f6-981d-7174dd3647af\", \"XC3_1_20210404_054400.csv\", 70116)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file downloaded to your local device.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **<------------ Part 2 ------------>**"
      ],
      "metadata": {
        "id": "BQ1pUokMea8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Creating Merged Dataframe Files**"
      ],
      "metadata": {
        "id": "SgD5AnLZeyrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 1: Change Working Directory**\n",
        "# Change working directory to defined path\n",
        "os.chdir('/content/drive/MyDrive/BirdnetProject/Files/data/CSV_data/XC')\n",
        "\n",
        "# Verify working directory\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2eNXtUgM2Gj",
        "outputId": "0a068d4a-359e-42aa-9019-02f2f53a746e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BirdnetProject/Files/data/CSV_data/XC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 2: Create Merged Dataframe File For All Transects**\n",
        "\n",
        "# Read in the CSV files\n",
        "df_XC1 = pd.read_csv('XC1_25_20230615_180000.csv')\n",
        "df_XC2 = pd.read_csv('XC2_25_20200530_171400.csv')\n",
        "df_XC3 = pd.read_csv('XC3_25_20210404_054400.csv')\n",
        "\n",
        "# Add a column to each dataframe to indicate the transect source\n",
        "df_XC1['transect'] = 1\n",
        "df_XC2['transect'] = 2\n",
        "df_XC3['transect'] = 3\n",
        "\n",
        "# Function to extract date and hour from the filename\n",
        "def extract_datetime(filename):\n",
        "    date_str = filename.split('_')[1]\n",
        "    time_str = filename.split('_')[2].split('.')[0]\n",
        "    datetime_str = date_str + ' ' + time_str\n",
        "    datetime = pd.to_datetime(datetime_str, format='%Y%m%d %H%M%S')\n",
        "    return datetime\n",
        "\n",
        "# Apply the function to create a new datetime column\n",
        "df_XC1['datetime'] = df_XC1['filename'].apply(extract_datetime)\n",
        "df_XC2['datetime'] = df_XC2['filename'].apply(extract_datetime)\n",
        "df_XC3['datetime'] = df_XC3['filename'].apply(extract_datetime)\n",
        "\n",
        "# Function to convert seconds to hour:minutes:seconds format based on the datetime\n",
        "def seconds_to_hms(datetime, seconds):\n",
        "    new_time = datetime + pd.to_timedelta(seconds, unit='s')\n",
        "    return new_time.strftime('%-H:%M:%S')\n",
        "\n",
        "# Apply the function to convert start_time and end_time\n",
        "df_XC1['start_time'] = df_XC1.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df_XC1['end_time'] = df_XC1.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "df_XC2['start_time'] = df_XC2.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df_XC2['end_time'] = df_XC2.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "df_XC3['start_time'] = df_XC3.apply(lambda row: seconds_to_hms(row['datetime'], row['start_time']), axis=1)\n",
        "df_XC3['end_time'] = df_XC3.apply(lambda row: seconds_to_hms(row['datetime'], row['end_time']), axis=1)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "concatenated_df = pd.concat([df_XC1, df_XC2], ignore_index=True)\n",
        "\n",
        "# Extract date and start hour\n",
        "concatenated_df['date'] = concatenated_df['datetime'].dt.date\n",
        "concatenated_df['start_hour'] = concatenated_df['datetime'].dt.hour\n",
        "\n",
        "# Sort the dataframe by transect, date, start_time, common_name, and confidence\n",
        "concatenated_df = concatenated_df.sort_values(by=['transect', 'date', 'start_time', 'common_name', 'confidence'])\n",
        "\n",
        "# Reorder the columns to have transect, date, start_hour, time, and readable start/end times\n",
        "reordered_columns = ['transect', 'date', 'start_hour', 'start_time', 'end_time', 'common_name', 'scientific_name', 'confidence', 'label', 'filename']\n",
        "concatenated_df = concatenated_df[reordered_columns]\n",
        "\n",
        "# Display the first few rows of the concatenated dataframe\n",
        "print(\"\\nNew Dataframe:\")\n",
        "print(concatenated_df.head())\n",
        "print(concatenated_df.tail())\n"
      ],
      "metadata": {
        "id": "CWSfo33QEApG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479334dd-be12-42b3-e028-18e44a1a653a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New Dataframe:\n",
            "   transect        date  start_hour start_time  end_time         common_name  \\\n",
            "0         1  2023-06-15          18   18:00:03  18:00:06   Eurasian Blackcap   \n",
            "1         1  2023-06-15          18   18:00:06  18:00:09   Eurasian Blackcap   \n",
            "2         1  2023-06-15          18   18:00:12  18:00:15   Eurasian Blackcap   \n",
            "3         1  2023-06-15          18   18:00:18  18:00:21  Eurasian Blackbird   \n",
            "4         1  2023-06-15          18   18:00:21  18:00:24   Eurasian Blackcap   \n",
            "\n",
            "      scientific_name  confidence                                 label  \\\n",
            "0  Sylvia atricapilla    0.490236  Sylvia atricapilla_Eurasian Blackcap   \n",
            "1  Sylvia atricapilla    0.586808  Sylvia atricapilla_Eurasian Blackcap   \n",
            "2  Sylvia atricapilla    0.568825  Sylvia atricapilla_Eurasian Blackcap   \n",
            "3       Turdus merula    0.417446      Turdus merula_Eurasian Blackbird   \n",
            "4  Sylvia atricapilla    0.774901  Sylvia atricapilla_Eurasian Blackcap   \n",
            "\n",
            "                  filename  \n",
            "0  XC1_20230615_180000.wav  \n",
            "1  XC1_20230615_180000.wav  \n",
            "2  XC1_20230615_180000.wav  \n",
            "3  XC1_20230615_180000.wav  \n",
            "4  XC1_20230615_180000.wav  \n",
            "     transect        date  start_hour start_time  end_time     common_name  \\\n",
            "150         2  2020-05-30          17   17:45:45  17:45:48  European Robin   \n",
            "151         2  2020-05-30          17   17:46:24  17:46:27  European Robin   \n",
            "152         2  2020-05-30          17   17:47:24  17:47:27  European Robin   \n",
            "153         2  2020-05-30          17   17:47:36  17:47:39  European Robin   \n",
            "154         2  2020-05-30          17   17:47:45  17:47:48  European Robin   \n",
            "\n",
            "        scientific_name  confidence                              label  \\\n",
            "150  Erithacus rubecula    0.662246  Erithacus rubecula_European Robin   \n",
            "151  Erithacus rubecula    0.394734  Erithacus rubecula_European Robin   \n",
            "152  Erithacus rubecula    0.289836  Erithacus rubecula_European Robin   \n",
            "153  Erithacus rubecula    0.254990  Erithacus rubecula_European Robin   \n",
            "154  Erithacus rubecula    0.331637  Erithacus rubecula_European Robin   \n",
            "\n",
            "                    filename  \n",
            "150  XC2_20200530_171400.wav  \n",
            "151  XC2_20200530_171400.wav  \n",
            "152  XC2_20200530_171400.wav  \n",
            "153  XC2_20200530_171400.wav  \n",
            "154  XC2_20200530_171400.wav  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 3: Decide Where to Save Files**\n",
        "# Ask the user where they want to save the CSV and Excel files\n",
        "save_option = input(\"Where would you like to save the files? Enter 'local' to download to your device or 'drive' to save to Google Drive: \")\n",
        "\n",
        "if save_option.lower() == 'drive':\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_path = input(\"Enter the path in your Google Drive where you want to save the files (e.g., /content/drive/MyDrive/BirdnetProject/Files/data/CSV_data/): \")\n",
        "    csv_output_path = os.path.join(drive_path, 'XC_25_Merged.csv')\n",
        "    excel_output_path = os.path.join(drive_path, 'XC_25_Merged.xlsx')\n",
        "    concatenated_df.to_csv(csv_output_path, index=False)\n",
        "    concatenated_df.to_excel(excel_output_path, index=False)\n",
        "    print(f\"CSV file saved to your Google Drive at {csv_output_path}\")\n",
        "    print(f\"Excel file saved to your Google Drive at {excel_output_path}\")\n",
        "elif save_option.lower() == 'local':\n",
        "    # Download the files to the user's local device\n",
        "    csv_output_path = 'XC_25_Merged.csv'\n",
        "    excel_output_path = 'XC_25_Merged.xlsx'\n",
        "    concatenated_df.to_csv(csv_output_path, index=False)\n",
        "    concatenated_df.to_excel(excel_output_path, index=False)\n",
        "    files.download(csv_output_path)\n",
        "    files.download(excel_output_path)\n",
        "    print(\"CSV and Excel files downloaded to your local device.\")\n",
        "else:\n",
        "    print(\"Invalid option. Please enter 'local' or 'drive'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "C8RgicXFMMDn",
        "outputId": "45a577fc-d9cc-44bf-9c6b-3a465f39541f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Where would you like to save the files? Enter 'local' to download to your device or 'drive' to save to Google Drive: local\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c2d39e66-39bc-46e4-8643-4202b95ccf37\", \"XC_25_Merged.csv\", 22627)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cf747206-a9fe-407a-9b04-b94658e2e0b5\", \"XC_25_Merged.xlsx\", 13799)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV and Excel files downloaded to your local device.\n"
          ]
        }
      ]
    }
  ]
}